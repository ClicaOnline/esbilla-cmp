# GTM Gateway Proxy - Infraestructura y Escalabilidad

**Fecha:** 2026-02-07
**Versi√≥n:** 1.8+
**Arquitectura:** Multi-tenant DNS-based proxy con escalabilidad modular

---

## üìñ Visi√≥n General

Este documento describe la arquitectura de infraestructura del GTM Gateway Proxy, dise√±ada para:

- ‚úÖ **Escalabilidad:** Soportar miles de clientes sin problemas de rate-limit o concurrencia
- ‚úÖ **Modularidad:** Cada componente puede escalar, mejorar y depurar independientemente
- ‚úÖ **Compliance GDPR:** Todas las regiones en zona UE (sin transferencia de datos fuera de UE)
- ‚úÖ **Alta disponibilidad:** 99.9% uptime con failover autom√°tico
- ‚úÖ **Performance:** Cache global con CDN, compresi√≥n Brotli, latencia <50ms

---

## üèóÔ∏è Arquitectura Modular

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      CLIENTE (Browser)                                 ‚îÇ
‚îÇ                 https://gtm.cliente.com/gtm.js                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     CAPA 1: Cloud CDN (Global)                         ‚îÇ
‚îÇ  PoPs: Frankfurt, London, Paris, Amsterdam, Mil√°n, Madrid             ‚îÇ
‚îÇ  - Cache en edge (TTL 5 min)                                          ‚îÇ
‚îÇ  - SSL/TLS termination                                                 ‚îÇ
‚îÇ  - DDoS protection                                                     ‚îÇ
‚îÇ  - Compresi√≥n Brotli/Gzip autom√°tica                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ (Cache MISS)
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              CAPA 2: Cloud Load Balancer (Multi-regi√≥n UE)             ‚îÇ
‚îÇ  Regiones: europe-west4 (NL), europe-west1 (BE), europe-west3 (DE)   ‚îÇ
‚îÇ  - Health checks autom√°ticos                                          ‚îÇ
‚îÇ  - Failover entre regiones                                            ‚îÇ
‚îÇ  - Balanceo por latencia                                              ‚îÇ
‚îÇ  - Rate limiting global                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         CAPA 3: Cloud Run (Compute - Auto-scaling)                     ‚îÇ
‚îÇ  Regiones: europe-west4 (primary), europe-west1 (secondary)          ‚îÇ
‚îÇ  Instancias: 1 m√≠nimo, 100 m√°ximo por regi√≥n                         ‚îÇ
‚îÇ  - Auto-scaling basado en CPU/requests                               ‚îÇ
‚îÇ  - In-memory cache por instancia (Map con TTL)                       ‚îÇ
‚îÇ  - Rate limiting por IP (10 req/min)                                 ‚îÇ
‚îÇ  - Identificaci√≥n multi-tenant via Host header                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              CAPA 4: Firestore (Database)                              ‚îÇ
‚îÇ  Regi√≥n: europe-west4 (Netherlands)                                   ‚îÇ
‚îÇ  - sites collection (lookup gtmGatewayDomain ‚Üí containerId)          ‚îÇ
‚îÇ  - Query cache (5 min)                                                ‚îÇ
‚îÇ  - Composite index: gtmGatewayDomain                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              CAPA 5: Google Tag Manager (External)                     ‚îÇ
‚îÇ  - googletagmanager.com (GTM-XXXXX)                                   ‚îÇ
‚îÇ  - G-XXXXX.fps.goog (GA4)                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîß Componentes Modulares

### 1. Cloud CDN (Capa de Cache Global)

**Responsabilidad:** Cache en edge locations cerca del usuario final.

**Configuraci√≥n:**
- **Backend:** Cloud Run via Load Balancer
- **Cache mode:** `CACHE_ALL_STATIC` con override por headers
- **TTL:** 5 minutos (configurable)
- **Compression:** Autom√°tica (Brotli/Gzip)
- **PoPs activos:** 6 en UE (Frankfurt, London, Paris, Amsterdam, Mil√°n, Madrid)

**Escalabilidad:**
- ‚úÖ **Horizontal:** A√±adir m√°s PoPs seg√∫n demanda geogr√°fica
- ‚úÖ **Cache hit rate:** Objetivo >80% (reduce carga a Cloud Run)
- ‚úÖ **Invalidaci√≥n:** Por path o wildcard si es necesario

**Beneficios:**
- Reduce latencia a <50ms para cache hits
- Reduce egress de Cloud Run en 80-90%
- DDoS protection autom√°tica

**Costos:**
- Cache ingress: ‚Ç¨0.02/GB (solo cache misses)
- Cache egress UE: ‚Ç¨0.04-0.08/GB (seg√∫n PoP)
- Cache hits: Gratis (solo egress del PoP)

**Configuraci√≥n GCP:**
```bash
# Habilitar Cloud CDN en backend service
gcloud compute backend-services update esbilla-api-backend \
  --enable-cdn \
  --cache-mode=CACHE_ALL_STATIC \
  --default-ttl=300 \
  --max-ttl=3600 \
  --client-ttl=300 \
  --global
```

---

### 2. Cloud Load Balancer (Capa de Distribuci√≥n)

**Responsabilidad:** Distribuir tr√°fico entre regiones y health checks.

**Configuraci√≥n:**
- **Tipo:** Global HTTP(S) Load Balancer
- **SSL:** Managed certificate (auto-renovaci√≥n)
- **Backend:** Cloud Run en 2-3 regiones UE
- **Health check:** `/api/health` cada 10s
- **Failover:** Autom√°tico si >50% instancias unhealthy
- **Timeout:** 30s
- **Balanceo:** Por latencia (env√≠a a regi√≥n m√°s cercana)

**Escalabilidad:**
- ‚úÖ **Multi-regi√≥n:** 2 regiones activas (NL + BE), 1 standby (DE)
- ‚úÖ **Failover autom√°tico:** Si region primary cae, traffic a secondary
- ‚úÖ **Rate limiting global:** 1000 req/s total (ajustable)

**Beneficios:**
- Alta disponibilidad (99.95% SLA)
- Failover autom√°tico sin downtime
- SSL/TLS termination centralizado
- Logs centralizados en Cloud Logging

**Costos:**
- Forwarding rules: ‚Ç¨0.025/hora (~‚Ç¨18/mes)
- Procesamiento: ‚Ç¨0.008 por 10,000 requests
- Egress a Cloud Run: Gratis (mismo proyecto)

**Configuraci√≥n GCP:**
```bash
# Crear load balancer con backends multi-regi√≥n
gcloud compute url-maps create esbilla-api-lb \
  --default-service=esbilla-api-backend

gcloud compute target-https-proxies create esbilla-api-proxy \
  --url-map=esbilla-api-lb \
  --ssl-certificates=esbilla-ssl-cert

gcloud compute forwarding-rules create esbilla-api-forwarding-rule \
  --global \
  --target-https-proxy=esbilla-api-proxy \
  --ports=443
```

---

### 3. Cloud Run (Capa de Compute)

**Responsabilidad:** Ejecutar l√≥gica de proxy (fetch a Google, cache, compresi√≥n).

**Configuraci√≥n por regi√≥n:**
- **Regi√≥n primary:** europe-west4 (Netherlands) - 80% del tr√°fico
- **Regi√≥n secondary:** europe-west1 (Belgium) - 20% del tr√°fico
- **Regi√≥n standby:** europe-west3 (Germany) - 0% (failover)

**Configuraci√≥n por instancia:**
- **CPU:** 1 vCPU
- **Memory:** 512 MB (suficiente para cache in-memory)
- **Min instances:** 1 (warm start)
- **Max instances:** 100 (auto-scaling)
- **Concurrency:** 80 requests por instancia
- **Timeout:** 60s
- **Startup time:** <5s (imagen optimizada)

**Auto-scaling triggers:**
- CPU > 70% ‚Üí +1 instancia
- Requests > 60/instancia ‚Üí +1 instancia
- CPU < 30% durante 5 min ‚Üí -1 instancia

**In-Memory Cache:**
- **Estructura:** `Map<string, CacheEntry>`
- **Key:** `gtm_${domain}_${containerId}_${dataLayer}`
- **TTL:** 5 minutos
- **Max size:** 100 containers (LRU eviction)
- **Tama√±o por entry:** ~80 KB (script GTM sin comprimir)
- **Total memory cache:** ~8 MB (despreciable vs 512 MB)

**Escalabilidad:**
- ‚úÖ **Horizontal:** Auto-scaling 1-100 instancias por regi√≥n
- ‚úÖ **Vertical:** Aumentar CPU/memory si es necesario
- ‚úÖ **Multi-regi√≥n:** A√±adir regiones adicionales (europe-west2, europe-north1)
- ‚úÖ **Desacoplado:** Cada instancia es stateless (cache local no cr√≠tico)

**Beneficios:**
- Pay-per-use (solo pagas por requests procesados)
- Auto-scaling sin intervenci√≥n manual
- Despliegue blue/green sin downtime
- Logs y m√©tricas en Cloud Logging/Monitoring

**Costos:**
- CPU: ‚Ç¨0.00002400/vCPU-s
- Memory: ‚Ç¨0.00000250/GB-s
- Requests: ‚Ç¨0.40 por mill√≥n
- **Ejemplo:** 1M requests/mes ‚âà ‚Ç¨5-10 (sin CDN), ‚Ç¨1-2 (con CDN)

**Configuraci√≥n GCP:**
```bash
# Deploy con configuraci√≥n de auto-scaling
gcloud run deploy esbilla-api \
  --image=gcr.io/esbilla-cmp/esbilla-api:latest \
  --region=europe-west4 \
  --min-instances=1 \
  --max-instances=100 \
  --concurrency=80 \
  --cpu=1 \
  --memory=512Mi \
  --timeout=60s \
  --allow-unauthenticated \
  --set-env-vars="GCLOUD_PROJECT=esbilla-cmp,FIRESTORE_DATABASE_ID=esbilla-cmp"
```

---

### 4. Firestore (Capa de Configuraci√≥n)

**Responsabilidad:** Almacenar configuraci√≥n de sites (gtmGatewayDomain ‚Üí containerId).

**Configuraci√≥n:**
- **Regi√≥n:** europe-west4 (Netherlands) - mismo datacenter que Cloud Run primary
- **Modo:** Native mode
- **Base de datos:** Named database `esbilla-cmp`

**Query cr√≠tico:**
```javascript
db.collection('sites')
  .where('gtmGatewayDomain', '==', 'gtm.cliente.com')
  .limit(1)
  .get()
```

**√çndice requerido:**
```json
{
  "collectionGroup": "sites",
  "queryScope": "COLLECTION",
  "fields": [
    { "fieldPath": "gtmGatewayDomain", "order": "ASCENDING" }
  ]
}
```

**Cache de queries:**
- **Estructura:** `Map<string, SiteConfig>`
- **Key:** `gtmGatewayDomain`
- **TTL:** 5 minutos
- **Invalidaci√≥n:** Manual si cambia configuraci√≥n en Dashboard

**Escalabilidad:**
- ‚úÖ **Reads:** Firestore escala autom√°ticamente (sin l√≠mite pr√°ctico)
- ‚úÖ **Cache:** Reduce reads en 95% (solo 1 query cada 5 min por dominio)
- ‚úÖ **Multi-region replication:** Firestore multi-region si es necesario

**Beneficios:**
- Query latency <10ms (misma regi√≥n que Cloud Run)
- Cache reduce costos de reads
- Firestore rules protegen contra acceso no autorizado

**Costos:**
- Reads: ‚Ç¨0.036 por 100,000 documentos
- **Ejemplo:** 1M requests ‚Üí 50,000 reads (con cache 95%) ‚Üí ‚Ç¨0.02/mes

---

### 5. Monitoring y Observabilidad

**Herramientas:**
- **Cloud Logging:** Logs estructurados de Cloud Run
- **Cloud Monitoring:** M√©tricas de CPU, memory, requests, latency
- **Cloud Trace:** Distributed tracing para debugging
- **Uptime Checks:** Monitoreo 24/7 desde m√∫ltiples regiones

**M√©tricas clave:**
- **Cache hit rate (CDN):** >80% esperado
- **Cache hit rate (in-memory):** >70% esperado
- **Latency p50:** <100ms
- **Latency p99:** <500ms
- **Error rate:** <0.1%
- **Availability:** >99.9%

**Alertas configuradas:**
- ‚ö†Ô∏è Error rate >1% durante 5 min ‚Üí Email + Slack
- ‚ö†Ô∏è Latency p99 >1s durante 5 min ‚Üí Email
- üö® Availability <99% durante 5 min ‚Üí PagerDuty
- ‚ö†Ô∏è Cloud Run instances >80 ‚Üí Email (escalar verticalmente)

**Logs importantes:**
```
[GTM Proxy] Multi-tenant routing: gtm.cliente.com ‚Üí site abc123 ‚Üí GTM-XXXXX
[GTM Proxy] Cache HIT para gtm.cliente.com (GTM-XXXXX)
[GTM Proxy] Cache MISS para gtm.cliente.com (GTM-XXXXX), fetching from Google...
[GTM Proxy] Cached gtm.cliente.com (GTM-XXXXX), size: 81234 bytes
[GTM Proxy] No site found for domain: gtm.noconfigurado.com
```

---

## üìä Estrategia de Escalabilidad

### Fase 1: MVP (0-100 clientes)
- ‚úÖ 1 regi√≥n (europe-west4)
- ‚úÖ Cloud Run: 1-10 instancias
- ‚úÖ Sin CDN (opcional)
- ‚úÖ Firestore cache 5 min
- **Capacidad:** ~10M requests/mes
- **Costo:** ~‚Ç¨5-15/mes

### Fase 2: Growth (100-1,000 clientes)
- ‚úÖ 2 regiones (europe-west4 + europe-west1)
- ‚úÖ Cloud Run: 1-50 instancias por regi√≥n
- ‚úÖ **Cloud CDN activado** (cr√≠tico para reducir costos)
- ‚úÖ Load Balancer con failover
- **Capacidad:** ~100M requests/mes
- **Costo:** ~‚Ç¨50-150/mes

### Fase 3: Scale (1,000-10,000 clientes)
- ‚úÖ 3 regiones (+ europe-west3 standby)
- ‚úÖ Cloud Run: 1-100 instancias por regi√≥n
- ‚úÖ CDN con 6 PoPs en UE
- ‚úÖ Firestore multi-region replication
- ‚úÖ Cloud Armor para DDoS protection
- **Capacidad:** ~1B requests/mes
- **Costo:** ~‚Ç¨500-1,500/mes

### Fase 4: Enterprise (10,000+ clientes)
- ‚úÖ 5+ regiones (toda Europa)
- ‚úÖ Cloud Run: 1-200 instancias por regi√≥n
- ‚úÖ CDN con cache optimizado (TTL m√°s largo)
- ‚úÖ Dedicated Load Balancer per client segment
- ‚úÖ Redis/Memorystore para cache compartido entre instancias
- ‚úÖ Cloud SQL para analytics de usage
- **Capacidad:** >10B requests/mes
- **Costo:** ~‚Ç¨5,000-15,000/mes

---

## üîê Compliance GDPR

**Todas las regiones en zona UE:**
- ‚úÖ europe-west4 (Netherlands)
- ‚úÖ europe-west1 (Belgium)
- ‚úÖ europe-west3 (Germany)
- ‚úÖ europe-west2 (UK) - opcional si Brexit no es problema
- ‚úÖ europe-north1 (Finland) - opcional para N√≥rdicos

**NO usar regiones fuera de UE:**
- ‚ùå us-central1, us-east1, us-west1 (EEUU)
- ‚ùå asia-southeast1, asia-east1 (Asia)
- ‚ùå australia-southeast1 (Australia)

**Justificaci√≥n:**
- **GDPR Art. 44-50:** Transferencia de datos fuera de UE requiere garant√≠as adicionales
- **Schrems II:** Cloud providers de EEUU (Google, AWS, Azure) tienen riesgo de acceso por FISA 702
- **Soluci√≥n:** Mantener TODOS los datos y procesamiento en UE elimina el problema

**Datos que NO salen de UE:**
- ‚úÖ Configuraci√≥n de sites (Firestore UE)
- ‚úÖ Logs de requests (Cloud Logging UE)
- ‚úÖ Cache in-memory (Cloud Run UE)
- ‚úÖ CDN cache (PoPs en UE)

**√önico dato fuera de UE:**
- ‚úÖ Fetch a Google Tag Manager (googletagmanager.com / fps.goog)
- ‚ö†Ô∏è Pero es necesario para funcionalidad (Google es el data processor)
- ‚úÖ No se env√≠an datos personales en el fetch (solo Container ID)

---

## üöÄ Despliegue Multi-Regi√≥n

### Terraform Configuration (Infraestructure as Code)

```hcl
# terraform/gtm-gateway/main.tf

variable "regions" {
  type = list(object({
    name = string
    weight = number
    min_instances = number
    max_instances = number
  }))
  default = [
    {
      name = "europe-west4"
      weight = 70
      min_instances = 1
      max_instances = 100
    },
    {
      name = "europe-west1"
      weight = 30
      min_instances = 1
      max_instances = 50
    },
    {
      name = "europe-west3"
      weight = 0  # standby
      min_instances = 0
      max_instances = 50
    }
  ]
}

# Cloud Run services per region
resource "google_cloud_run_service" "esbilla_api" {
  for_each = { for r in var.regions : r.name => r }

  name     = "esbilla-api"
  location = each.value.name

  template {
    spec {
      containers {
        image = "gcr.io/esbilla-cmp/esbilla-api:latest"
        resources {
          limits = {
            cpu    = "1"
            memory = "512Mi"
          }
        }
      }
    }

    metadata {
      annotations = {
        "autoscaling.knative.dev/minScale" = each.value.min_instances
        "autoscaling.knative.dev/maxScale" = each.value.max_instances
        "run.googleapis.com/execution-environment" = "gen2"
      }
    }
  }

  traffic {
    percent         = 100
    latest_revision = true
  }
}

# Backend service con Cloud CDN
resource "google_compute_backend_service" "esbilla_api" {
  name        = "esbilla-api-backend"
  protocol    = "HTTPS"
  timeout_sec = 30

  enable_cdn = true
  cdn_policy {
    cache_mode        = "CACHE_ALL_STATIC"
    default_ttl       = 300
    max_ttl           = 3600
    client_ttl        = 300
    negative_caching  = false
  }

  dynamic "backend" {
    for_each = var.regions
    content {
      group = google_cloud_run_service.esbilla_api[backend.value.name].status[0].url
      balancing_mode = "UTILIZATION"
      capacity_scaler = backend.value.weight / 100
    }
  }

  health_checks = [google_compute_health_check.esbilla_api.id]
}

# Health check
resource "google_compute_health_check" "esbilla_api" {
  name               = "esbilla-api-health"
  check_interval_sec = 10
  timeout_sec        = 5

  https_health_check {
    port         = 443
    request_path = "/api/health"
  }
}

# Load Balancer
resource "google_compute_url_map" "esbilla_api" {
  name            = "esbilla-api-lb"
  default_service = google_compute_backend_service.esbilla_api.id
}

# SSL certificate
resource "google_compute_managed_ssl_certificate" "esbilla_api" {
  name = "esbilla-api-ssl"

  managed {
    domains = ["api.esbilla.com"]
  }
}

# HTTPS proxy
resource "google_compute_target_https_proxy" "esbilla_api" {
  name             = "esbilla-api-proxy"
  url_map          = google_compute_url_map.esbilla_api.id
  ssl_certificates = [google_compute_managed_ssl_certificate.esbilla_api.id]
}

# Forwarding rule (IP p√∫blica)
resource "google_compute_global_forwarding_rule" "esbilla_api" {
  name       = "esbilla-api-forwarding-rule"
  target     = google_compute_target_https_proxy.esbilla_api.id
  port_range = "443"
  ip_protocol = "TCP"
}
```

**Desplegar con Terraform:**
```bash
cd terraform/gtm-gateway
terraform init
terraform plan
terraform apply
```

---

## üß™ Testing de Escalabilidad

### Load Testing con k6

```javascript
// load-test.js
import http from 'k6/http';
import { check, sleep } from 'k6';

export let options = {
  stages: [
    { duration: '2m', target: 100 },   // Ramp-up a 100 usuarios
    { duration: '5m', target: 100 },   // Mantener 100 usuarios
    { duration: '2m', target: 500 },   // Ramp-up a 500 usuarios
    { duration: '5m', target: 500 },   // Mantener 500 usuarios
    { duration: '2m', target: 1000 },  // Ramp-up a 1000 usuarios
    { duration: '5m', target: 1000 },  // Mantener 1000 usuarios
    { duration: '3m', target: 0 },     // Ramp-down a 0
  ],
};

export default function () {
  const domains = [
    'gtm.cliente1.com',
    'gtm.cliente2.com',
    'gtm.cliente3.com',
    // ... 100 dominios diferentes para simular multi-tenancy
  ];

  const domain = domains[Math.floor(Math.random() * domains.length)];

  const res = http.get(`https://${domain}/gtm.js`, {
    headers: { 'Host': domain }
  });

  check(res, {
    'status 200': (r) => r.status === 200,
    'latency < 500ms': (r) => r.timings.duration < 500,
    'has X-Cache header': (r) => r.headers['X-Cache'] !== undefined,
  });

  sleep(1);
}
```

**Ejecutar load test:**
```bash
k6 run --vus 1000 --duration 30m load-test.js
```

**Objetivos:**
- ‚úÖ 0% error rate
- ‚úÖ p50 latency <100ms
- ‚úÖ p99 latency <500ms
- ‚úÖ Cache hit rate >80%
- ‚úÖ Auto-scaling funciona correctamente

---

## üí∞ Proyecci√≥n de Costos por Fase

### Fase 1: MVP (100 clientes, 10M req/mes)
| Componente | Costo/mes |
|------------|-----------|
| Cloud Run (1 regi√≥n) | ‚Ç¨5 |
| Firestore reads | ‚Ç¨0.02 |
| Egress (sin CDN) | ‚Ç¨25 |
| **Total** | **‚Ç¨30** |

### Fase 2: Growth (1,000 clientes, 100M req/mes)
| Componente | Costo/mes |
|------------|-----------|
| Cloud Run (2 regiones) | ‚Ç¨15 |
| Cloud CDN cache | ‚Ç¨10 |
| Cloud CDN egress | ‚Ç¨40 |
| Load Balancer | ‚Ç¨18 |
| Firestore reads | ‚Ç¨0.20 |
| Monitoring | ‚Ç¨5 |
| **Total** | **‚Ç¨88** |

### Fase 3: Scale (10,000 clientes, 1B req/mes)
| Componente | Costo/mes |
|------------|-----------|
| Cloud Run (3 regiones) | ‚Ç¨50 |
| Cloud CDN cache | ‚Ç¨100 |
| Cloud CDN egress | ‚Ç¨400 |
| Load Balancer | ‚Ç¨18 |
| Firestore reads | ‚Ç¨2 |
| Monitoring | ‚Ç¨20 |
| **Total** | **‚Ç¨590** |

**Pricing para clientes:**
- Fase 1: ‚Ç¨10-15/mes por cliente (margen 50%)
- Fase 2: ‚Ç¨15-25/mes por cliente (margen 70%)
- Fase 3: ‚Ç¨20-30/mes por cliente (margen 80%)

---

## üéØ Conclusi√≥n

Esta arquitectura modular permite:

1. ‚úÖ **Escalar horizontalmente** a√±adiendo regiones o instancias seg√∫n demanda
2. ‚úÖ **Escalar verticalmente** aumentando CPU/memory de Cloud Run si es necesario
3. ‚úÖ **Aislar componentes** para debug y mejoras independientes:
   - CDN: Ajustar cache TTL o a√±adir PoPs
   - Load Balancer: Cambiar algoritmo de balanceo o a√±adir regiones
   - Cloud Run: Optimizar c√≥digo, a√±adir instancias o cambiar configuraci√≥n
   - Firestore: Optimizar queries o a√±adir √≠ndices
4. ‚úÖ **Cumplir GDPR** manteniendo TODO el procesamiento en UE
5. ‚úÖ **Alta disponibilidad** con failover autom√°tico y multi-regi√≥n
6. ‚úÖ **Costos predecibles** con pricing por cliente transparente

**Pr√≥ximos pasos:**
1. Implementar Terraform config para despliegue automatizado
2. Configurar Cloud CDN con backends multi-regi√≥n
3. A√±adir monitoring y alertas
4. Load testing con k6
5. Documentar runbooks de incidencias

---

üåΩ **Esbilla CMP** ‚Äî Consent management made in Asturias
